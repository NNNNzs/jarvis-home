# ============================================
# JARVIS Home - 环境变量配置示例
# ============================================
# 复制此文件为 .env 并填入实际值
# 注意: .env 文件已加入 .gitignore，不会提交到版本控制
#
# 详细说明请查看: docs/env-variables.md

# ============================================
# 1. 服务器配置
# ============================================

# 服务监听端口（默认: 3000）
PORT=3000

# 运行环境（development | production，默认: development）
NODE_ENV=development

# CORS 允许的来源，多个用逗号分隔，* 表示允许所有（默认: *）
# 示例: http://localhost:3000,https://yourdomain.com
ALLOWED_ORIGINS=*

# ============================================
# 2. LLM 服务配置 (用于意图识别和计划生成)
# ============================================
# 注意:
# - LLM 和 Embeddings 可以使用不同的接口地址
# - 可以同时配置两个提供商，通过 LLM_PROVIDER 明确指定使用哪个
# - 两个提供商都支持自定义 baseURL（通过代理或兼容 API）

# 明确指定使用的提供商 (anthropic | openai)
# 如果未指定，将按优先级自动选择: anthropic > openai
# 如果同时配置了两个 API Key，强烈建议设置此变量
LLM_PROVIDER=anthropic

# ============================================
# 2.1 Anthropic Claude 配置
# ============================================

# Anthropic API 密钥（使用 Anthropic 时必需）
# 类型: string
# 必需: 条件（使用 Anthropic 时必需）
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# Anthropic 自定义接口地址（可选）
# 类型: string
# 必需: ❌
# 支持通过代理或兼容 API 使用
# 示例:
#   - https://api.anthropic.com
#   - https://your-proxy.com/v1
ANTHROPIC_BASE_URL=

# Anthropic 模型名称（可选，默认: claude-3-5-sonnet-20241022）
# 类型: string
# 必需: ❌
# 注意: 如果使用 OpenAI，此变量会被忽略，需要单独设置或使用默认值
LLM_MODEL=claude-3-5-sonnet-20241022

# ============================================
# 2.2 OpenAI 配置
# ============================================

# OpenAI API 密钥（使用 OpenAI 时必需）
# 类型: string
# 必需: 条件（使用 OpenAI 时必需）
OPENAI_API_KEY=sk-your-openai-api-key-here

# OpenAI 自定义接口地址（可选）
# 类型: string
# 必需: ❌
# 支持通过代理或兼容 API 使用
# 示例:
#   - https://api.openai.com/v1
#   - https://your-proxy.com/v1
OPENAI_BASE_URL=

# OpenAI 模型名称（可选，默认: gpt-4o-mini）
# 类型: string
# 必需: ❌
# 注意: 如果使用 Anthropic，此变量会被忽略
# LLM_MODEL=gpt-4o-mini

# ============================================
# 3. 向量模型配置 (用于文本嵌入和相似度搜索)
# ============================================
# 注意:
# - 向量模型可以与 LLM 使用完全不同的接口地址
# - 向量模型服务是可选的，未配置不影响基本功能
# - 如果配置，需要同时提供 API_KEY、BASE_URL 和 MODEL

# 向量模型 API 密钥（必需，如果使用 embeddings 功能）
# 类型: string
# 必需: ✅（如果使用 embeddings 功能）
EMBEDDING_API_KEY=your-embedding-api-key-here

# 向量模型接口地址（必需，如果使用 embeddings 功能）
# 类型: string
# 必需: ✅（如果使用 embeddings 功能）
# 示例:
#   - SiliconFlow: https://api.siliconflow.cn/v1
#   - OpenAI: https://api.openai.com/v1
#   - 自定义代理: https://your-proxy.com/v1
EMBEDDING_BASE_URL=https://api.siliconflow.cn/v1

# 向量模型名称（必需，如果使用 embeddings 功能）
# 类型: string
# 必需: ✅（如果使用 embeddings 功能）
# 示例:
#   - SiliconFlow: BAAI/bge-large-zh-v1.5
#   - OpenAI: text-embedding-3-small
EMBEDDING_MODEL=BAAI/bge-large-zh-v1.5

# 向量模型提供商（可选: openai | siliconflow）
# 类型: string
# 必需: ❌
# 默认根据 baseURL 推断，但可以明确指定
EMBEDDING_PROVIDER=siliconflow

# 向量维度（可选，某些模型支持自定义维度）
# 类型: number
# 必需: ❌
# EMBEDDING_DIMENSIONS=1024

# ============================================
# 4. Home Assistant 配置 (可选)
# ============================================
# 注意: 如果未配置，系统将运行在演示模式（不控制真实设备）

# Home Assistant 实例地址（必需，如果使用真实设备控制）
# 类型: string
# 必需: ✅（如果使用真实设备控制）
# 示例:
#   - http://homeassistant.local:8123
#   - http://192.168.1.100:8123
HOME_ASSISTANT_URL=http://homeassistant.local:8123

# Home Assistant 长生命周期访问令牌（必需，如果使用真实设备控制）
# 类型: string
# 必需: ✅（如果使用真实设备控制）
# 获取方式:
#   1. 登录 Home Assistant
#   2. 进入 "用户配置" → "安全"
#   3. 创建 "长生命周期访问令牌"
#   4. 复制到 .env 文件
HOME_ASSISTANT_TOKEN=your-ha-long-lived-access-token-here

# ============================================
# 5. 缓存配置 (可选)
# ============================================

# 缓存策略（默认: context_aware）
# 类型: string
# 默认值: context_aware
# 可选值:
#   - context_aware: 基于上下文感知的智能缓存（推荐）
#   - simple: 简单缓存策略
CACHE_STRATEGY=context_aware

# 缓存过期时间（秒，默认: 3600，即1小时）
# 类型: number
# 默认值: 3600
CACHE_TTL=3600

# 缓存最大条目数（默认: 50）
# 类型: number
# 默认值: 50
CACHE_MAX_SIZE=50

# ============================================
# 配置说明和示例
# ============================================
#
# 最小配置（仅测试）:
#   - OPENAI_API_KEY 或 ANTHROPIC_API_KEY（二选一）
#
# 示例 - 最小配置:
#   OPENAI_API_KEY=sk-your-key-here
#
# 推荐配置（生产环境）:
#   - LLM_PROVIDER（明确指定使用哪个提供商）
#   - 对应的 LLM API Key 和 BASE_URL（如需要）
#   - EMBEDDING_API_KEY + EMBEDDING_BASE_URL + EMBEDDING_MODEL（如使用 embeddings）
#   - HOME_ASSISTANT_URL + HOME_ASSISTANT_TOKEN（如需要真实设备控制）
#
# 示例 - LLM 和 Embeddings 使用不同接口:
#   LLM_PROVIDER=openai
#   OPENAI_API_KEY=sk-openai-key-here
#   OPENAI_BASE_URL=https://api.openai.com/v1
#   EMBEDDING_API_KEY=sk-siliconflow-key-here
#   EMBEDDING_BASE_URL=https://api.siliconflow.cn/v1
#   EMBEDDING_MODEL=BAAI/bge-large-zh-v1.5
#
# 示例 - 同时配置两个 LLM 提供商:
#   LLM_PROVIDER=anthropic
#   ANTHROPIC_API_KEY=sk-ant-key-here
#   ANTHROPIC_BASE_URL=https://proxy.example.com/v1
#   OPENAI_API_KEY=sk-openai-key-here
#   OPENAI_BASE_URL=https://api.openai.com/v1
#
# 示例 - 完整生产配置:
#   PORT=3000
#   NODE_ENV=production
#   ALLOWED_ORIGINS=https://yourdomain.com
#   LLM_PROVIDER=anthropic
#   ANTHROPIC_API_KEY=sk-ant-key-here
#   ANTHROPIC_BASE_URL=https://api.anthropic.com
#   LLM_MODEL=claude-3-5-sonnet-20241022
#   EMBEDDING_API_KEY=sk-sf-key-here
#   EMBEDDING_BASE_URL=https://api.siliconflow.cn/v1
#   EMBEDDING_MODEL=BAAI/bge-large-zh-v1.5
#   HOME_ASSISTANT_URL=http://192.168.1.100:8123
#   HOME_ASSISTANT_TOKEN=your-ha-token-here
#   CACHE_STRATEGY=context_aware
#   CACHE_TTL=3600
#   CACHE_MAX_SIZE=100
#
# 重要提示:
#   1. LLM 和 Embeddings 可以独立配置
#      - 可以使用不同的 API Key
#      - 可以使用不同的接口地址（baseURL）
#      - 可以使用不同的提供商
#   2. 必需 vs 可选
#      - 必需: LLM 服务（OPENAI_API_KEY 或 ANTHROPIC_API_KEY）
#      - 可选: Embeddings 服务、Home Assistant
#   3. 环境变量优先级
#      - 如果设置了 LLM_PROVIDER，严格按照指定值使用
#      - 如果未设置 LLM_PROVIDER，自动选择: ANTHROPIC_API_KEY > OPENAI_API_KEY
#      - 如果未配置任何 LLM API Key，系统无法启动
#   4. 安全建议
#      - 不要将 .env 文件提交到版本控制
#      - 生产环境使用环境变量或密钥管理服务
#      - 定期轮换 API Key
#
# 更多配置示例和说明，请查看: docs/env-variables.md
